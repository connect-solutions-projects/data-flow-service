name: data-flow

networks:
  dev_net:
    name: dev_net
    external: true   # rede criada pelo docker-compose.infrastructure.yml

services:
  proxy:
    image: nginx:1.27-alpine
    container_name: data-flow-proxy
    ports:
      - "8080:80"
      - "8443:443"
      - "8081:8081"
      - "8444:8444"
    volumes:
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./certs:/etc/nginx/certs:ro
    depends_on:
      - data-flow-api
      - data-flow-reporting
    networks:
      - dev_net
    restart: unless-stopped
    profiles: ["proxy"]

  # ──────────────────────────────────────────────
  # API principal (DataFlow.Api)
  # ──────────────────────────────────────────────
  data-flow-api:
    container_name: api
    pull_policy: never
    build:
      context: .                                # build no root do repo
      dockerfile: src/apps/DataFlow.Api/Dockerfile
    expose:
      - "8080"
    environment:
      ASPNETCORE_URLS: http://0.0.0.0:8080
      DOTNET_ENVIRONMENT: ${ASPNETCORE_ENV:-Development}

      # Conexões apontando para os containers da rede dev_net
      ConnectionStrings__DataFlow: "Data Source=sqlserver,1433;Initial Catalog=DataFlowDev;User ID=sa;Password=${SQLSERVER_SA_PASSWORD:-DataFlow@Dolar$};Encrypt=True;TrustServerCertificate=True"
      ConnectionStrings__Redis: "redis:6379"
      Rabbit__Connection: "amqp://${RABBITMQ_USER:-admin}:${RABBITMQ_PASSWORD:-supersecret_admin}@rabbitmq:5672/"

      # Import Storage
      ImportStorage__BasePath: "/var/dataflow/imports"
      
      # OmniFlow
      OmniFlow__BaseUrl: "${OMNIFLOW_BASE_URL:-http://omniflow-api:5000}"
      
      # Import Batch
      ImportBatch__ChunkSize: "${IMPORT_BATCH_CHUNK_SIZE:-100}"
      ImportBatch__PollIntervalSeconds: "${IMPORT_BATCH_POLL_INTERVAL:-30}"
      ImportBatch__LockTimeoutMinutes: "${IMPORT_BATCH_LOCK_TIMEOUT:-30}"
      ImportBatch__MaxRetries: "${IMPORT_BATCH_MAX_RETRIES:-3}"
      REDIS__HOST: redis
      REDIS__PORT: "6379"
      RABBIT__HOST: rabbitmq
      RABBIT__PORT: "5672"
      RABBIT__USER: "${RABBITMQ_USER:-admin}"
      RABBIT__PASSWORD: "${RABBITMQ_PASSWORD:-supersecret_admin}"
      RABBIT__VHOST: "/"
      RabbitMq__Host: rabbitmq
      RabbitMq__Port: "5672"
      RabbitMq__Username: "${RABBITMQ_USER:-admin}"
      RabbitMq__Password: "${RABBITMQ_PASSWORD:-supersecret_admin}"
      RabbitMq__VirtualHost: "/"
      # OpenTelemetry OTLP endpoint
      OTEL_EXPORTER_OTLP_ENDPOINT: "http://otel-collector:4317"
      # Variáveis usadas pelo wait-for-rabbit.sh
      RABBITMQ_HOST: rabbitmq
      RABBITMQ_USER: admin
      RABBITMQ_PASSWORD: supersecret_admin
      RABBITMQ_MGMT_PORT: "15672"
      ClientSeed__Clients__0__Name: "Local Test"
      ClientSeed__Clients__0__ClientIdentifier: "local-client"
      ClientSeed__Clients__0__Secret: "local-secret-123"
    volumes:
      - dataflow_imports:/var/dataflow/imports
    networks:
      - dev_net
    restart: unless-stopped
    profiles: ["api"]

  # ──────────────────────────────────────────────
  # Worker de processamento (DataFlow.Worker)
  # ──────────────────────────────────────────────
  data-flow-worker:
    container_name: worker
    pull_policy: never
    build:
      context: .                                # também builda do root
      dockerfile: src/apps/DataFlow.Worker/Dockerfile
    expose:
      - "9090"  # Prometheus metrics endpoint
    environment:
      DOTNET_ENVIRONMENT: ${ASPNETCORE_ENV:-Development}
      ConnectionStrings__DataFlow: "Data Source=sqlserver,1433;Initial Catalog=DataFlowDev;User ID=sa;Password=${SQLSERVER_SA_PASSWORD:-DataFlow@Dolar$};Encrypt=True;TrustServerCertificate=True"
      ConnectionStrings__Redis: "redis:6379"
      Rabbit__Connection: "amqp://${RABBITMQ_USER:-admin}:${RABBITMQ_PASSWORD:-supersecret_admin}@rabbitmq:5672/"
      
      # Import Storage
      ImportStorage__BasePath: "/var/dataflow/imports"
      
      # OmniFlow
      OmniFlow__BaseUrl: "${OMNIFLOW_BASE_URL:-http://omniflow-api:5000}"
      
      # Import Batch
      ImportBatch__ChunkSize: "${IMPORT_BATCH_CHUNK_SIZE:-100}"
      ImportBatch__PollIntervalSeconds: "${IMPORT_BATCH_POLL_INTERVAL:-30}"
      ImportBatch__LockTimeoutMinutes: "${IMPORT_BATCH_LOCK_TIMEOUT:-30}"
      ImportBatch__MaxRetries: "${IMPORT_BATCH_MAX_RETRIES:-3}"
      REDIS__HOST: redis
      REDIS__PORT: "6379"
      RABBIT__HOST: rabbitmq
      RABBIT__PORT: "5672"
      RABBIT__USER: "${RABBITMQ_USER:-admin}"
      RABBIT__PASSWORD: "${RABBITMQ_PASSWORD:-supersecret_admin}"
      RABBIT__VHOST: "/"
      RabbitMq__Host: rabbitmq
      RabbitMq__Port: "5672"
      RabbitMq__Username: "${RABBITMQ_USER:-admin}"
      RabbitMq__Password: "${RABBITMQ_PASSWORD:-supersecret_admin}"
      RabbitMq__VirtualHost: "/"
      # OpenTelemetry OTLP endpoint
      OTEL_EXPORTER_OTLP_ENDPOINT: "http://otel-collector:4317"
    volumes:
      - dataflow_imports:/var/dataflow/imports
    networks:
      - dev_net
    restart: unless-stopped
    profiles: ["worker"]

  
  # ──────────────────────────────────────────────
  # Reporting Service (DataFlow.ReportingService)
  # ──────────────────────────────────────────────
  data-flow-reporting:
    container_name: reporting
    pull_policy: never
    build:
      context: .                                # builda do root
      dockerfile: src/apps/DataFlow.ReportingService/Dockerfile
    expose:
      - "8080"
    environment:
      ASPNETCORE_URLS: http://0.0.0.0:8080
    networks:
      - dev_net
    restart: unless-stopped
    profiles: ["reporting"]

volumes:
  dataflow_imports:
    driver: local
