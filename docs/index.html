<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="UTF-8" />
  <title>DataFlow — Documentação Consolidada</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    :root {
      --bg: #f5f5f5;
      --bg-alt: #ffffff;
      --border: #dddddd;
      --text-main: #222222;
      --text-muted: #666666;
      --accent: #2563eb;
      --accent-soft: #e0ecff;
    }

    * {
      box-sizing: border-box;
    }

    body {
      margin: 0;
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
      background: var(--bg);
      color: var(--text-main);
      line-height: 1.6;
    }

    header {
      background: #ffffff;
      border-bottom: 1px solid var(--border);
      padding: 0.75rem 1.5rem;
      position: sticky;
      top: 0;
      z-index: 10;
    }

    .header-inner {
      max-width: 1080px;
      margin: 0 auto;
      display: flex;
      flex-wrap: wrap;
      align-items: center;
      justify-content: space-between;
      gap: 0.75rem;
    }

    .brand {
      font-weight: 600;
      font-size: 1rem;
    }

    .brand span {
      color: var(--accent);
    }

    nav {
      display: flex;
      flex-wrap: wrap;
      gap: 0.5rem;
      font-size: 0.85rem;
    }

    nav a {
      text-decoration: none;
      color: var(--text-muted);
      padding: 0.25rem 0.6rem;
      border-radius: 999px;
    }

    nav a:hover {
      background: var(--accent-soft);
      color: var(--accent);
    }

    .layout {
      max-width: 1080px;
      margin: 1.5rem auto 2rem;
      padding: 0 1.5rem;
      display: grid;
      grid-template-columns: minmax(0, 250px) minmax(0, 1fr);
      gap: 1.5rem;
    }

    @media (max-width: 860px) {
      .layout {
        grid-template-columns: minmax(0, 1fr);
      }
    }

    aside {
      background: var(--bg-alt);
      border-radius: 10px;
      border: 1px solid var(--border);
      padding: 1rem 1.1rem;
      font-size: 0.85rem;
    }

    .toc-title {
      font-size: 0.8rem;
      text-transform: uppercase;
      letter-spacing: 0.12em;
      color: var(--text-muted);
      margin-bottom: 0.5rem;
    }

    .toc-section {
      margin-top: 0.6rem;
      font-weight: 600;
      font-size: 0.8rem;
      color: var(--text-muted);
      text-transform: uppercase;
    }

    .toc-list {
      list-style: none;
      padding-left: 0;
      margin: 0.2rem 0 0.2rem;
    }

    .toc-list li {
      margin-bottom: 0.18rem;
    }

    .toc-list a {
      text-decoration: none;
      color: var(--text-muted);
      font-weight: 400;
    }

    .toc-list a:hover {
      color: var(--accent);
    }

    main {
      background: var(--bg-alt);
      border-radius: 10px;
      border: 1px solid var(--border);
      padding: 1.4rem 1.5rem 1.6rem;
    }

    h1 {
      font-size: 1.4rem;
      margin-top: 0;
      margin-bottom: 0.4rem;
    }

    .intro {
      font-size: 0.95rem;
      color: var(--text-muted);
      margin-bottom: 1rem;
    }

    section {
      margin-top: 1.2rem;
      padding-top: 1rem;
      border-top: 1px solid #eeeeee;
    }

    section:first-of-type {
      border-top: none;
      padding-top: 0.5rem;
    }

    h2 {
      font-size: 1.1rem;
      margin: 0 0 0.4rem;
    }

    h3 {
      font-size: 0.98rem;
      margin: 0.7rem 0 0.3rem;
    }

    p {
      margin: 0.25rem 0 0.4rem;
      font-size: 0.92rem;
    }

    ul {
      margin: 0.1rem 0 0.5rem 1.1rem;
      padding-left: 0;
      font-size: 0.9rem;
    }

    li {
      margin-bottom: 0.2rem;
    }

    code {
      font-family: SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      background: #f3f4f6;
      padding: 0.08rem 0.25rem;
      border-radius: 4px;
      font-size: 0.85rem;
    }

    pre {
      background: #f3f4f6;
      border-radius: 6px;
      padding: 0.6rem 0.7rem;
      overflow-x: auto;
      font-size: 0.85rem;
    }

    pre code {
      background: transparent;
      padding: 0;
    }

    .box {
      border-radius: 8px;
      border: 1px solid #e5e7eb;
      background: #fafafa;
      padding: 0.6rem 0.75rem;
      margin-top: 0.4rem;
      font-size: 0.9rem;
    }

    .muted {
      color: var(--text-muted);
      font-size: 0.9rem;
    }

    .columns-2 {
      display: grid;
      grid-template-columns: minmax(0, 1fr) minmax(0, 1fr);
      gap: 1rem;
      margin-top: 0.4rem;
    }

    @media (max-width: 720px) {
      .columns-2 {
        grid-template-columns: minmax(0, 1fr);
      }
    }

    footer {
      max-width: 1080px;
      margin: 0 auto 1.5rem;
      padding: 0 1.5rem;
      font-size: 0.8rem;
      color: var(--text-muted);
      margin-top: -0.5rem;
    }
  </style>
</head>
<body>
  <header>
    <div class="header-inner">
      <div class="brand">DataFlow — <span>Documentação</span></div>
      <nav aria-label="Navegação rápida">
        <a href="#visao-geral">Visão geral</a>
        <a href="#arquitetura">Arquitetura</a>
        <a href="#decisoes">Decisões</a>
        <a href="#operacoes">Operações</a>
        <a href="#endpoints">Endpoints</a>
        <a href="#observabilidade">Grafana/Prometheus</a>
        <a href="#scripts">Scripts</a>
        <a href="#templates">Relatórios</a>
      </nav>
    </div>
  </header>

  <div class="layout">
    <aside>
      <div class="toc-title">Sumário</div>

      <div class="toc-section">Fundamentos</div>
      <ul class="toc-list">
        <li><a href="#visao-geral">Visão geral do projeto</a></li>
        <li><a href="#estrutura-docs">Estrutura da documentação</a></li>
      </ul>

      <div class="toc-section">Arquitetura</div>
      <ul class="toc-list">
        <li><a href="#arquitetura">Arquitetura técnica</a></li>
        <li><a href="#decisoes">Decisões técnicas</a></li>
      </ul>

      <div class="toc-section">Operação</div>
      <ul class="toc-list">
        <li><a href="#operacoes">Instalação e stack Docker</a></li>
        <li><a href="#fora-docker">Execução fora do Docker</a></li>
        <li><a href="#openssl">OpenSSL no PATH</a></li>
      </ul>

      <div class="toc-section">Uso diário</div>
      <ul class="toc-list">
        <li><a href="#endpoints">Guia de endpoints</a></li>
        <li><a href="#observabilidade">Grafana &amp; Prometheus</a></li>
        <li><a href="#scripts">Scripts úteis</a></li>
        <li><a href="#templates">Modelo de relatório</a></li>
      </ul>
    </aside>

    <main>
      <h1>DataFlow — Documentação Consolidada</h1>
      <p class="intro">
        Esta página resume os principais documentos do projeto DataFlow: visão geral, arquitetura,
        operações, uso dos endpoints, observabilidade e modelo de relatório final.
      </p>

      <!-- VISÃO GERAL -->
      <section id="visao-geral">
        <h2>1. Visão geral do projeto</h2>
        <p>
          O DataFlow é uma plataforma de ingestão assíncrona construída em .NET 9, organizada em monorepo
          e focada em receber arquivos de grande porte, processá-los em background e expor métricas e relatórios
          através de uma stack containerizada com Docker Compose.
        </p>
        <div class="box">
          <strong>Objetivo principal:</strong> permitir ingestão de arquivos grandes de forma segura e observável,
          desacoplando o upload (API) do processamento (Workers) e oferecendo relatórios prontos ao final dos testes.
        </div>
      </section>

      <section id="estrutura-docs">
        <h2>2. Estrutura da documentação</h2>
        <p>Os materiais de apoio do projeto estão organizados em três pastas principais:</p>
        <ul>
          <li><code>architecture/</code> — diagramas, visão técnica detalhada e decisões de arquitetura.</li>
          <li><code>operations/</code> — guias de instalação, testes, tutoriais e evidências.</li>
          <li><code>templates/</code> — modelos reutilizáveis (por exemplo, relatório final).</li>
        </ul>
        <p class="muted">
          Recomenda-se começar pela preparação de ambiente, depois ler a arquitetura e por fim seguir os tutoriais de endpoints
          e geração de relatórios.
        </p>
      </section>

      <!-- ARQUITETURA -->
      <section id="arquitetura">
        <h2>3. Arquitetura técnica (resumo)</h2>
        <p>
          A arquitetura do DataFlow segue separação em serviços e camadas, com comunicação assíncrona e observabilidade nativa.
        </p>
        <h3>3.1 Serviços principais</h3>
        <ul>
          <li><strong>DataFlow.Api</strong> — expõe endpoints para upload de arquivos, valida metadados, registra jobs e publica mensagens no RabbitMQ.</li>
          <li><strong>DataFlow.Worker</strong> — consome mensagens, executa o pipeline de processamento (leitura, validação, persistência) e atualiza o estado do job.</li>
          <li><strong>DataFlow.ReportingService</strong> — consulta métricas no Prometheus, usa (quando necessário) links/imagens de dashboards Grafana e gera relatórios em Markdown.</li>
          <li><strong>Proxy Nginx</strong> — termina TLS e roteia chamadas externas para API e Reporting.</li>
        </ul>

        <h3>3.2 Componentes de infraestrutura</h3>
        <ul>
          <li><strong>RabbitMQ</strong> — fila de mensagens que desacopla a API dos Workers.</li>
          <li><strong>Redis</strong> — coordenação (locks, deduplicação) e cache leve.</li>
          <li><strong>PostgreSQL</strong> — persistência dos jobs e demais dados.</li>
          <li><strong>OpenTelemetry Collector + Prometheus + Grafana</strong> — trilha completa de observabilidade.</li>
        </ul>

        <h3>3.3 Organização do monorepo</h3>
        <pre><code>src/
  apps/
    DataFlow.Api/
    DataFlow.Worker/
    DataFlow.ReportingService/
  libs/
    DataFlow.Core.Domain/
    DataFlow.Core.Application/
    DataFlow.Infrastructure/
    DataFlow.Observability/
    DataFlow.Shared/
docs/
  architecture/
  operations/
  templates/
scripts/
  certs/
  diagrams/
  ingestion/</code></pre>
      </section>

      <!-- DECISÕES TÉCNICAS -->
      <section id="decisoes">
        <h2>4. Decisões técnicas de ingestão e processamento</h2>
        <p>
          Algumas decisões importantes foram registradas especificamente para a parte de ingestão e processamento assíncrono.
        </p>

        <div class="columns-2">
          <div>
            <h3>4.1 API de ingestão HTTP</h3>
            <ul>
              <li>Endpoint principal: <code>POST /ingestion/jobs</code>.</li>
              <li>Valida metadados (clientId, fileType, checksum) e produz mensagem com o contexto do job.</li>
              <li>Publica na fila (RabbitMQ) usando hostnames internos da rede Docker.</li>
            </ul>

            <h3>4.2 Fila, Workers e Redis</h3>
            <ul>
              <li><strong>RabbitMQ</strong>: garante ACKs, reentregas e escalabilidade de consumidores.</li>
              <li><strong>Workers</strong>: executam o pipeline de leitura, transformação, validação e persistência.</li>
              <li><strong>Redis</strong>: suporta locks, deduplicação de jobs e cache de dados transitórios.</li>
            </ul>
          </div>
          <div>
            <h3>4.3 Observabilidade e relatórios</h3>
            <ul>
              <li>OpenTelemetry Collector recebe traces e métricas de API/Worker.</li>
              <li>Prometheus armazena séries temporais (latência, taxas, erros).</li>
              <li>Grafana visualiza as métricas e gera imagens via Image Renderer.</li>
              <li>ReportingService consolida indicadores em arquivos Markdown prontos para uso.</li>
            </ul>
          </div>
        </div>
      </section>

      <!-- OPERAÇÕES -->
      <section id="operacoes">
        <h2>5. Operações, instalação e testes</h2>
        <p>
          O modo de operação suportado oficialmente é via Docker Compose, a partir de uma máquina Windows 10/11 com PowerShell
          e Docker Desktop.
        </p>

        <h3>5.1 Pré-requisitos principais</h3>
        <ul>
          <li>Windows 10/11 com PowerShell.</li>
          <li>Docker Desktop com Docker Compose v2.</li>
          <li>Opcional: .NET 9 SDK e Node.js (para rodar serviços fora do Docker e renderizar diagramas Mermaid).</li>
        </ul>

        <h3>5.2 Passos resumidos</h3>
        <ol>
          <li>Clonar o repositório e abrir PowerShell na raiz.</li>
          <li>Gerar certificados de desenvolvimento:
            <pre><code>scripts\certs\generate-dev-certs.cmd</code></pre>
          </li>
          <li>Configurar hostnames no arquivo <code>hosts</code>:
            <pre><code>127.0.0.1 api.local
127.0.0.1 reporting.local</code></pre>
          </li>
          <li>Criar a rede Docker (caso ainda não exista):
            <pre><code>docker network create docker-network</code></pre>
          </li>
          <li>Subir dependências e observabilidade:
            <pre><code>docker compose up -d postgres redis rabbitmq otel-collector prometheus grafana-renderer grafana</code></pre>
          </li>
          <li>Subir API, Worker, Reporting e proxy:
            <pre><code>docker compose --profile proxy --profile api --profile worker --profile reporting up -d</code></pre>
          </li>
        </ol>

        <h3>5.3 Health checks e testes básicos</h3>
        <ul>
          <li>Grafana: <code>http://localhost:3000</code></li>
          <li>Prometheus: <code>http://localhost:9090</code></li>
          <li>API via proxy: <code>https://api.local:8443/health</code></li>
          <li>Reporting via proxy: <code>https://reporting.local:8444/health</code></li>
        </ul>

        <div class="box">
          Critérios de aceite sugeridos: latência p95 ≤ 500 ms, erros 5xx &lt; 1% e quantidade de requisições ativas estável
          durante a janela de teste.
        </div>
      </section>

      <!-- FORA DO DOCKER -->
      <section id="fora-docker">
        <h2>6. Execução fora do Docker (modo manual)</h2>
        <p>
          Executar o DataFlow fora do Docker é opcional e exige configuração manual de Postgres, Redis, RabbitMQ e (se desejado)
          do stack de observabilidade.
        </p>

        <h3>6.1 Checklist básico</h3>
        <ul>
          <li>.NET 9 SDK instalado.</li>
          <li>PostgreSQL 15+ com banco e usuário configurados (por exemplo, <code>dataflow</code> / <code>dataflow_admin</code>).</li>
          <li>Redis e RabbitMQ em execução.</li>
          <li>Variáveis de ambiente para strings de conexão (Postgres, Redis, RabbitMQ).</li>
          <li>Migrations aplicadas com <code>dotnet ef database update</code>.</li>
        </ul>

        <h3>6.2 Execução dos serviços</h3>
        <p>Exemplos (PowerShell):</p>
        <pre><code># API
cd src\apps\DataFlow.Api
dotnet run

# Worker
cd src\apps\DataFlow.Worker
dotnet run

# ReportingService
cd src\apps\DataFlow.ReportingService
dotnet run</code></pre>
        <p class="muted">
          Nesse modo, Swagger fica exposto nas portas de desenvolvimento (por exemplo,
          <code>https://localhost:5001/swagger</code>). Se quiser manter <code>api.local</code> e <code>reporting.local</code>,
          é preciso configurar um proxy reverso local.
        </p>
      </section>

      <!-- OPENSSL -->
      <section id="openssl">
        <h2>7. OpenSSL no PATH do PowerShell</h2>
        <p>
          Alguns scripts de certificado dependem do OpenSSL. Em geral, ele vem junto com o Git for Windows e fica em:
        </p>
        <pre><code>C:\Program Files\Git\usr\bin\openssl.exe</code></pre>
        <p>Há duas formas comuns de adicionar ao PATH:</p>
        <ul>
          <li><strong>Temporário</strong> (apenas sessão atual do PowerShell) — alterar <code>$env:Path</code>.</li>
          <li><strong>Permanente</strong> — via interface gráfica de variáveis de ambiente ou via comando PowerShell rodando como Administrador.</li>
        </ul>
        <p class="muted">
          Depois de ajustar o PATH, use <code>openssl version</code> para conferir se o comando está acessível.
        </p>
      </section>

      <!-- ENDPOINTS -->
      <section id="endpoints">
        <h2>8. Guia de endpoints — API e Reporting</h2>
        <p>
          O guia de endpoints descreve como chamar os serviços principais do DataFlow (API e Reporting) quando a stack está
          rodando com proxy.
        </p>

        <div class="columns-2">
          <div>
            <h3>8.1 Configuração de hostnames</h3>
            <p>Com Docker + proxy padrão:</p>
            <ul>
              <li>API: <code>https://api.local:8443</code></li>
              <li>Reporting: <code>https://reporting.local:8444</code></li>
            </ul>
            <p class="muted">
              Se não quiser editar o arquivo <code>hosts</code>, é possível adaptar o
              <code>docker-compose.yml</code> e a configuração do Nginx para usar <code>localhost</code>.
            </p>

            <h3>8.2 Script auxiliar de parâmetros</h3>
            <p>Use o batch para calcular checksum e metadados do arquivo:</p>
            <pre><code>scripts\ingestion\gera-parametros.bat</code></pre>
            <p>Ele imprime:</p>
            <ul>
              <li><code>checksum</code> (SHA-256)</li>
              <li><code>fileName</code>, <code>fileSize</code>, <code>contentType</code></li>
              <li><code>fileType=csv</code> (nesta demo)</li>
            </ul>
          </div>
          <div>
            <h3>8.3 API de ingestão (DataFlow.Api)</h3>
            <ul>
              <li><strong>Health</strong>: <code>GET /health</code></li>
              <li><strong>Criar job</strong>: <code>POST /ingestion/jobs</code> (multipart/form-data)</li>
              <li><strong>Consultar job</strong>: <code>GET /ingestion/jobs/{id}</code></li>
              <li><strong>Reprocessar</strong>:
                <ul>
                  <li><code>POST /ingestion/jobs/{id}/process</code></li>
                  <li><code>POST /ingestion/jobs/{id}/retry</code></li>
                  <li><code>POST /ingestion/jobs/{id}/reprocess</code></li>
                </ul>
              </li>
              <li><strong>Uploads no storage</strong>: <code>GET /storage/uploads</code></li>
            </ul>

            <h3>8.4 Reporting Service</h3>
            <ul>
              <li><strong>Health</strong>: <code>GET /health</code></li>
              <li><strong>Relatório final</strong>: <code>POST /reports/final</code> (JSON com <code>job</code>, <code>window</code>, <code>outputDir</code>).</li>
              <li><strong>Relatório de exemplo</strong>: <code>GET /reports/sample</code>.</li>
            </ul>
          </div>
        </div>
      </section>

      <!-- OBSERVABILIDADE -->
      <section id="observabilidade">
        <h2>9. Observabilidade com Grafana e Prometheus</h2>
        <p>
          O projeto inclui um guia específico para uso de Grafana e Prometheus, cobrindo desde o fluxo de dados até as consultas
          PromQL mais comuns.
        </p>

        <h3>9.1 Fluxo de dados de observabilidade</h3>
        <pre><code>API / Worker → OpenTelemetry → OTel Collector → Prometheus → Grafana
                                                 ↓
                                         Reporting Service</code></pre>

        <h3>9.2 Principais URLs</h3>
        <ul>
          <li>Prometheus: <code>http://localhost:9090</code></li>
          <li>Grafana: <code>http://localhost:3000</code></li>
        </ul>

        <h3>9.3 Consultas PromQL úteis</h3>
        <ul>
          <li>Taxa de requisições (5m): <code>rate(http_requests_total[5m])</code></li>
          <li>Latência p95:
            <code>histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))</code>
          </li>
          <li>Requisições por status:
            <code>sum by(status) (rate(http_requests_total[5m]))</code>
          </li>
          <li>Rate limit 429:
            <code>rate(dataflow_rate_limit_429_total[5m])</code>
          </li>
          <li>Deduplicação:
            <code>rate(dataflow_deduplication_hits_total[5m])</code>
          </li>
        </ul>

        <h3>9.4 Integração com o Reporting Service</h3>
        <p>
          O ReportingService consulta Prometheus, gera links de dashboards Grafana (e imagens via Image Renderer, quando habilitado)
          e monta um relatório em Markdown com métricas, gráficos e observações.
        </p>
      </section>

      <!-- SCRIPTS -->
      <section id="scripts">
        <h2>10. Scripts úteis do projeto</h2>
        <p>Os scripts foram organizados por finalidade na pasta <code>scripts/</code>:</p>

        <h3>10.1 Certificados</h3>
        <ul>
          <li><code>scripts/certs/generate-dev-certs.ps1</code> e <code>.cmd</code> — geram certificados para <code>api.local</code> e <code>reporting.local</code>.</li>
        </ul>

        <h3>10.2 Ingestão</h3>
        <ul>
          <li><code>scripts/ingestion/gera-parametros.bat</code> — calcula checksum e metadados do arquivo.</li>
          <li><code>scripts/ingestion/gerar-csv-grande.ps1/.cmd</code> — gera um CSV grande para testes,
            salvo em <code>files/large-test-data.csv</code>.</li>
        </ul>

        <h3>10.3 Diagramas</h3>
        <ul>
          <li><code>scripts/diagrams/render_mermaid_diagram.ps1/.cmd</code> — renderiza o diagrama Mermaid de arquitetura em PNG/SVG via <code>mermaid-cli</code>.</li>
        </ul>

        <p class="muted">
          O guia de scripts explica como executar cada utilitário e quais parâmetros estão disponíveis.
        </p>
      </section>

      <!-- TEMPLATES / RELATÓRIO -->
      <section id="templates">
        <h2>11. Templates e modelo de relatório final</h2>
        <p>
          A pasta <code>templates/</code> concentra modelos reutilizáveis. O principal é o
          <code>modelo-relatorio-final.md</code>, usado como referência ou base para o arquivo gerado pelo
          ReportingService.
        </p>

        <h3>11.1 Estrutura sugerida do relatório</h3>
        <ul>
          <li><strong>Resumo executivo</strong> — objetivo do teste, escopo e principais achados.</li>
          <li><strong>Estado do stack</strong> — serviços ativos na <code>docker-network</code> e datasources Grafana.</li>
          <li><strong>Métricas principais</strong> — taxa de requisições, latência p95, distribuição por status.</li>
          <li><strong>Dashboards e imagens</strong> — links do Grafana e PNGs exportados.</li>
          <li><strong>Operações executadas</strong> — comandos, scripts e janela de análise.</li>
          <li><strong>Resultados e observações</strong> — anomalias, riscos, limitações e insights.</li>
          <li><strong>Próximos passos</strong> — recomendações após o teste.</li>
          <li><strong>Anexos</strong> — logs e referências relevantes.</li>
        </ul>

        <p class="muted">
          O ReportingService pode preencher grande parte dessas seções automaticamente, gerando o Markdown em um diretório
          como <code>docs/reports</code>.
        </p>
      </section>
    </main>
  </div>

  <footer>
    DataFlow — página única em HTML estático para leitura, envio por e-mail ou publicação interna.
  </footer>
</body>
</html>
